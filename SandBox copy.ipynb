{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-craps",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "916a5b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 35 100]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "shape = np.stack([\n",
    "    35,\n",
    "    100\n",
    "], axis=0)\n",
    "\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-anaheim",
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_dataset import generator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-cisco",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_path = os.getcwd() + \"\\\\..\\\\data\\\\sample_data\\\\train\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datanetAPI import DatanetAPI\n",
    "#https://github.com/knowledgedefinednetworking/datanetAPI/tree/challenge2020\n",
    "import networkx as nx\n",
    "\n",
    "tool = DatanetAPI(tr_path)\n",
    "it = iter(tool)\n",
    "for sample in it:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-brother",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-assurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = sample.topology_object\n",
    "nx.draw_networkx(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.edges, len(network.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for edge in network.edges:\n",
    "    print(network.edges[edge[0],edge[1],edge[2]])\n",
    "    i+=1\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "network[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# routing matrix tells you the path that needs to be taken for every source-dest node pair\n",
    "\n",
    "print(sample.get_routing_matrix()[0])\n",
    "print(sample.get_routing_matrix()[1])\n",
    "print(sample.get_routing_matrix().shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "routing = sample.get_routing_matrix()\n",
    "paths = routing[~np.eye(routing.shape[0], dtype=bool)].reshape(routing.shape[0], -1)\n",
    "print(routing.shape, paths.shape)\n",
    "paths = paths.flatten()\n",
    "print(paths.shape, paths[:2],paths[98])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_mat = np.full((network.number_of_nodes(), network.number_of_nodes()), fill_value=None)\n",
    "for node in range(network.number_of_nodes()):\n",
    "    for adj in network[node]:\n",
    "        cap_mat[node, adj] = network[node][adj][0]['bandwidth']\n",
    "\n",
    "print(cap_mat)\n",
    "# take the indexes of where there is capacity and turn into a list\n",
    "links = np.where(np.ravel(cap_mat) != None)[0].tolist()\n",
    "link_capacities = (np.ravel(cap_mat)[links]).tolist()\n",
    "len(links),len(link_capacities),links[:10],link_capacities[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nodes = len(routing)\n",
    "ids = list(range(len(links)))\n",
    "\n",
    "links_id = dict(zip(links, ids))\n",
    "path_ids = []\n",
    "for path in paths:                    # 182 lists of node sequences (src-> int -> .... -> dest)\n",
    "    new_path = [] \n",
    "    for i in range(0, len(path) - 1): # number of nodes in the specific src,dest path... minus 1\n",
    "        src = path[i]                 # break path into series of single hops (src,int1) (int1,int2) (int2,dst)\n",
    "        dst = path[i + 1]\n",
    "        new_path.append(links_id[src * nodes + dst])     # grabs the id of the link between each single hop (src,dest)\n",
    "    path_ids.append(new_path)                            # aggregates a list of links used in all paths, links can be\n",
    "                                                         # used more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert paths from path described by nodes and turn into paths defined by links\n",
    "len(path_ids),path_ids[98],paths[98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ids[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_indices = []\n",
    "path_indices = []\n",
    "sequ_indices = []\n",
    "segment = 0                                         \n",
    "for p in path_ids:\n",
    "    link_indices += p\n",
    "    path_indices += len(p) * [segment]\n",
    "    sequ_indices += list(range(len(p)))\n",
    "    segment += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take path list and flatten into single individual list\n",
    "# list of all links used in all paths, list of which path each link belongs to, which number each link is as part of its path\n",
    "link_indices[:5],path_indices[:5],sequ_indices[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(link_indices),len(path_indices),len(sequ_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-director",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic = sample.get_traffic_matrix()\n",
    "traffic = traffic[~np.eye(traffic.shape[0], dtype=bool)].reshape(traffic.shape[0], -1)\n",
    "traffic.shape\n",
    "traffic[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sample.get_performance_matrix()\n",
    "result = result[~np.eye(result.shape[0], dtype=bool)].reshape(result.shape[0], -1)\n",
    "print(result.shape)\n",
    "\n",
    "sample.get_performance_matrix()[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-pierce",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_bw = []\n",
    "pkts_gen = []\n",
    "delay = []\n",
    "########## critical information here #############\n",
    "for i in range(result.shape[0]):\n",
    "    for j in range(result.shape[1]):\n",
    "        flow = traffic[i, j]['Flows'][0]\n",
    "        avg_bw.append(flow['AvgBw'])\n",
    "        pkts_gen.append(flow['PktsGen'])\n",
    "        d = result[i, j]['AggInfo']['AvgDelay']\n",
    "        delay.append(d)\n",
    "\n",
    "n_paths = len(path_ids)\n",
    "n_links = max(max(path_ids)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-central",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_paths = len(path_ids)\n",
    "n_links = max(max(path_ids)) + 1\n",
    "n_links,n_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(avg_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-delight",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch, delay in generator(tr_path):\n",
    "    x = batch\n",
    "    y = delay\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-mention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this sample the capacity matrix is 14 x 14 and they remove the entries along the diagonal and then they flatten it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-attitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x['bandwith']),len(x['bandwith']),x['bandwith'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-standing",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x['packets']),len(x['packets']),x['packets'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x['link_capacity']),len(x['link_capacity']),x['link_capacity'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-airline",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "type(x['links']),len(x['links']),x['links'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "x['n_paths'],len(x['paths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-england",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(y),y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-boulder",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
